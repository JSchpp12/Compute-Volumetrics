#version 450

layout(local_size_x = 8, local_size_y = 8, local_size_z = 1) in;

struct Light_Type
{
    uint point;
    uint directional;
    uint spot;
};

struct Light
{
    vec4 position;
    vec4 direction;

    // properties
    vec4 ambient;
    vec4 diffuse;
    vec4 specular;
    // controls.x = inner cutoff angle
    // controls.y = outer cutoff angle
    vec4 controls;
    // settings.x = enabled
    // settings.y = type
    uvec4 settings;
};

layout(set = 0, binding = 0) uniform GlobalUniformBufferObject
{
    mat4 proj;
    mat4 view;
    mat4 inverseView;
} globalUbo;

layout(set = 0, binding = 1) uniform GlobalLightInfo{
    int numLights;
} lightInfo; 

layout(set = 0, binding = 2) readonly buffer GlobalLightBuffer{
    Light lights[];
 } lightList;

layout(set = 1, binding = 0) uniform additionalCameraInfo
{
    mat4 inverseProjMatrix;
    vec2 cameraDimensions;
    float aspectRatio;
    float farClipDist;
    float nearClipDist;
    float scale;
}
addCamInfo;
layout(std430, set = 1, binding = 1) buffer PNanoVDBBuffer{
    uint pnanovdb_buf_data[];
};

layout(set = 2, binding = 0, rgba8) uniform readonly image2D inputSceneColor;
layout(set = 2, binding = 1) uniform sampler2D inputSceneDepth;
layout(set = 2, binding = 2, rgba8) uniform writeonly image2D outputImage;

layout(set = 3, binding = 0) uniform InstanceModelMatrix
{
    mat4 modelMatrix[1024];
};

layout(set = 3, binding = 1) uniform aabbInfo
{
    vec4 bounds[2];
}
aabb;

layout(set = 3, binding = 2) uniform FogControllerInfo
{
    float linearFog_nearDistance;
    float linearFog_farDistance;
    float expFog_density;
    float marchedFog_defaultDensity;
    float marchedFog_sigmaAbsorption;
    float marchedFog_sigmaScattering;
    float marchedFog_lightPropertyDirG;
    float marchedFog_stepSizeDist;
    float marchedFog_stepSizeDist_light;
    uint marchedFog_levelSet_maxNumSteps;
    uint gridType;
}
fogInfo;

struct Ray
{
    vec4 origin;
    vec4 direction;
    vec4 invDirection;
    bool signed[3];
};

#include "PNanoVDB.h"
#include "volume_helpers.comp"

Ray createRay(const vec4 origin, const vec4 direction)
{
    vec3 invDir = vec3(1.0 / direction.x, 1.0 / direction.y, 1.0 / direction.z);

    return Ray(origin, direction, vec4(invDir, 0.0),
               bool[3](bool(invDir.x < 0), bool(invDir.y < 0), bool(invDir.z < 0)));
}

vec4 getClipSpaceCoordsFromPixel(const ivec2 pixelCoords, const float ndz){
    // 1) Build NDC coordinates in [−1, +1]
    float ndcX = ((float(pixelCoords.x) + 0.5) / addCamInfo.cameraDimensions.x) * 2.0 - 1.0;
    float ndcY = ((float(pixelCoords.y) + 0.5) / addCamInfo.cameraDimensions.y) * 2.0 - 1.0;

    // Vulkan's Y axis is flipped compared to OpenGL
    ndcY = -ndcY; 

    // 2) Reconstruct clip-space with Z = −1 (the near plane), W = 1
    return vec4(ndcX, ndcY, ndz, 1.0);
}

vec4 getWorldPositionFromClip(const vec4 clipCoords){
    // 3) Go back to view-space:
    vec4 viewPositionWorld = addCamInfo.inverseProjMatrix * clipCoords;

    return viewPositionWorld / viewPositionWorld.w; 
}

vec4 getWorldViewDirection(const vec4 viewPositionWorld){
    return vec4(normalize((globalUbo.inverseView * vec4(viewPositionWorld.xyz, 0.0)).xyz), 0);
}

vec4 getWorldOrigin(){
    return vec4((globalUbo.inverseView * vec4(0.0, 0.0, 0.0, 1.0)).xyz, 1.0);
}

ivec2 getTargetPixelCoords()
{
    return ivec2((gl_LocalInvocationID.x) + ((gl_WorkGroupID.x) * 8),
                 (gl_LocalInvocationID.y) + ((gl_WorkGroupID.y) * 8));
}

float linearizeDepth(const float depth, const float camNearClipDist, const float camFarClipDist)
{
    /* convert depth value back to linear space -- based on proj matrix
    Source: http://www.songho.ca/opengl/gl_projectionmatrix.html
    Source2: https://learnopengl.com/Advanced-OpenGL/Depth-testing
    */
    return (camNearClipDist * camFarClipDist) / (camFarClipDist - depth * (camFarClipDist - camNearClipDist));
}

bool checkForThreadOutsideOfTarget()
{
    ivec2 imageSize = imageSize(inputSceneColor);
    uvec2 coords = gl_GlobalInvocationID.xy;
    if (coords.x > imageSize.x || coords.y > imageSize.y)
    {
        return false;
    }

    return true;
}

bool rayBoxIntersect(in pnanovdb_grid_handle_t grid, in Ray ray, inout float t0, inout float t1)
{
    vec3 bounds[2];
    bounds[0] = vec3(
        float(pnanovdb_grid_get_world_bbox(nanoVDBBuffer, grid, 0)),
        float(pnanovdb_grid_get_world_bbox(nanoVDBBuffer, grid, 1)),
        float(pnanovdb_grid_get_world_bbox(nanoVDBBuffer, grid, 2))
    );
    bounds[1] = vec3(
        float(pnanovdb_grid_get_world_bbox(nanoVDBBuffer, grid, 3)),
        float(pnanovdb_grid_get_world_bbox(nanoVDBBuffer, grid, 4)), 
        float(pnanovdb_grid_get_world_bbox(nanoVDBBuffer, grid, 5))
    );

    float tmin = -(1.0 / 0.0);
    float tmax = (1.0 / 0.0);
    float txmin = 0, txmax = 0, tymin = 0, tymax = 0, tzmin = 0, tzmax = 0;

    txmin = (bounds[int(ray.signed[0])].x - ray.origin.x) * ray.invDirection.x;
    txmax = (bounds[int(!ray.signed[0])].x - ray.origin.x) * ray.invDirection.x;

    tmin = min(txmin, txmax);
    tmax = max(txmin, txmax);

    tymin = (bounds[int(ray.signed[1])].y - ray.origin.y) * ray.invDirection.y;
    tymax = (bounds[int(!ray.signed[1])].y - ray.origin.y) * ray.invDirection.y;

    tmin = max(tmin, min(tymin, tymax));
    tmax = min(tmax, max(tymin, tymax));

    tzmin = (bounds[int(ray.signed[2])].z - ray.origin.z) * ray.invDirection.z;
    tzmax = (bounds[int(!ray.signed[2])].z - ray.origin.z) * ray.invDirection.z;

    tmin = max(tmin, min(tzmin, tzmax));
    tmax = min(tmax, max(tzmin, tzmax));

    t0 = tmin;
    t1 = tmax;

    return tmax >= max(0.0, tmin);
}

float applyHenyeyGreensteinPhase(const vec3 viewDirection, const vec3 lightDirection, const float gValue){
    const float cosTheta = dot(viewDirection, lightDirection); 
    const float denom = pow(1 + gValue * gValue - 2 * gValue * cosTheta, 1.5);
    return float(1) / (4 * radians(180)) * (1 - gValue * gValue) / denom; 
}

void main()
{
    if (!checkForThreadOutsideOfTarget())
        return;

    const ivec2 targetPixel = getTargetPixelCoords();
    float targetPixelInputDepth = texelFetch(inputSceneDepth, targetPixel, 0).r;

    const vec4 clipSpace = getClipSpaceCoordsFromPixel(targetPixel, targetPixelInputDepth); 
    const vec4 viewPositionWorld = getWorldPositionFromClip(clipSpace);
    const vec4 orgWorld = getWorldOrigin(); 
    const vec4 viewDirectionWorld = getWorldViewDirection(viewPositionWorld); 
    const float worldDepthDistance = length(viewPositionWorld.xyz - viewDirectionWorld.xyz); 

    const vec3 imgColor = vec3(imageLoad(inputSceneColor, targetPixel).rgb);
    vec4 resultingColor = vec4(imgColor, 1.0);

    pnanovdb_grid_handle_t grid = makeNanoGrid(0); 

    Ray camRay = createRay(orgWorld, viewDirectionWorld);

    float t0 = 0;
    float t1 = 0;

    if (rayBoxIntersect(grid, camRay, t0, t1) && t0 < worldDepthDistance){
        resultingColor = vec4(1.0, 0.0, 0.0, 1.0); 
    }

    imageStore(outputImage, targetPixel, resultingColor);
}