#version 450

layout(local_size_x = 8, local_size_y = 8, local_size_z = 1) in;

struct Light_Type
{
    uint point;
    uint directional;
    uint spot;
};

struct Light
{
    vec4 position;
    vec4 direction;

    // properties
    vec4 ambient;
    vec4 diffuse;
    vec4 specular;
    // controls.x = inner cutoff angle
    // controls.y = outer cutoff angle
    vec4 controls;
    // settings.x = enabled
    // settings.y = type
    uvec4 settings;
};

layout(set = 0, binding = 0) uniform GlobalUniformBufferObject
{
    mat4 proj;
    mat4 view;
    mat4 inverseView;
} globalUbo;

layout(set = 0, binding = 1) uniform GlobalLightInfo{
    int numLights;
} lightInfo; 

layout(set = 0, binding = 2) readonly buffer GlobalLightBuffer{
    Light lights[];
 } lightList;

layout(set = 1, binding = 0) uniform additionalCameraInfo
{
    mat4 inverseProjMatrix;
    vec2 cameraDimensions;
    float aspectRatio;
    float farClipDist;
    float nearClipDist;
    float scale;
}
addCamInfo;
layout(std430, set = 1, binding = 1) buffer PNanoVDBBuffer{
    uint pnanovdb_buf_data[];
};

layout(set = 2, binding = 0, rgba8) uniform readonly image2D inputSceneColor;
layout(set = 2, binding = 1) uniform sampler2D inputSceneDepth;
layout(set = 2, binding = 2, rgba8) uniform writeonly image2D outputImage;

layout(set = 3, binding = 0) uniform InstanceModelMatrix
{
    mat4 instanceModelMatrix[1024];
};

layout(set = 3, binding = 1) uniform aabbInfo
{
    vec4 bounds[2];
}
aabb;

layout(set = 3, binding = 2) uniform FogControllerInfo
{
    float linearFog_nearDistance;
    float linearFog_farDistance;
    float expFog_density;
    float marchedFog_defaultDensity;
    float marchedFog_sigmaAbsorption;
    float marchedFog_sigmaScattering;
    float marchedFog_lightPropertyDirG;
    float marchedFog_stepSizeDist;
    float marchedFog_stepSizeDist_light;
    uint marchedFog_levelSet_maxNumSteps;
    uint gridType;
}
fogInfo;

#include "PNanoVDB.h"
#include "volume_helpers.comp"

vec4 getClipSpaceCoordsFromPixel(const ivec2 pixelCoords, const float ndz){
    // 1) Build NDC coordinates in [−1, +1]
    float ndcX = ((float(pixelCoords.x) + 0.5) / addCamInfo.cameraDimensions.x) * 2.0 - 1.0;
    float ndcY = ((float(pixelCoords.y) + 0.5) / addCamInfo.cameraDimensions.y) * 2.0 - 1.0;

    // Vulkan's Y axis is flipped compared to OpenGL
    ndcY = -ndcY; 

    // 2) Reconstruct clip-space with Z = −1 (the near plane), W = 1
    return vec4(ndcX, ndcY, ndz, 1.0);
}

vec4 getWorldPositionFromClip(const vec4 clipCoords){
    // 3) Go back to view-space:
    vec4 viewPositionWorld = addCamInfo.inverseProjMatrix * clipCoords;

    return viewPositionWorld / viewPositionWorld.w; 
}

vec4 getWorldViewDirection(const vec4 viewPositionWorld){
    return vec4(normalize((globalUbo.inverseView * vec4(viewPositionWorld.xyz, 0.0)).xyz), 0);
}

vec4 getWorldOrigin(){
    return vec4((globalUbo.inverseView * vec4(0.0, 0.0, 0.0, 1.0)).xyz, 1.0);
}

ivec2 getTargetPixelCoords()
{
    return ivec2((gl_LocalInvocationID.x) + ((gl_WorkGroupID.x) * 8),
                 (gl_LocalInvocationID.y) + ((gl_WorkGroupID.y) * 8));
}

float linearizeDepth(const float depth, const float camNearClipDist, const float camFarClipDist)
{
    /* convert depth value back to linear space -- based on proj matrix
    Source: http://www.songho.ca/opengl/gl_projectionmatrix.html
    Source2: https://learnopengl.com/Advanced-OpenGL/Depth-testing
    */
    return (camNearClipDist * camFarClipDist) / (camFarClipDist - depth * (camFarClipDist - camNearClipDist));
}

bool checkForThreadOutsideOfTarget()
{
    ivec2 imageSize = imageSize(inputSceneColor);
    uvec2 coords = gl_GlobalInvocationID.xy;
    if (coords.x > imageSize.x || coords.y > imageSize.y)
    {
        return false;
    }

    return true;
}

float applyHenyeyGreensteinPhase(const vec3 viewDirection, const vec3 lightDirection, const float gValue){
    const float cosTheta = dot(viewDirection, lightDirection); 
    const float denom = pow(1 + gValue * gValue - 2 * gValue * cosTheta, 1.5);
    return float(1) / (4 * radians(180)) * (1 - gValue * gValue) / denom; 
}

void main()
{
    if (!checkForThreadOutsideOfTarget())
        return;

    const ivec2 targetPixel = getTargetPixelCoords();
    float targetPixelInputDepth = texelFetch(inputSceneDepth, targetPixel, 0).r;

    const vec4 clipSpace = getClipSpaceCoordsFromPixel(targetPixel, targetPixelInputDepth); 
    const vec4 viewPositionWorld = getWorldPositionFromClip(clipSpace);
    const vec4 orgWorld = getWorldOrigin(); 
    const vec4 viewDirectionWorld = getWorldViewDirection(viewPositionWorld); 
    const float worldDepthDistance = length(viewPositionWorld.xyz - viewDirectionWorld.xyz); 

    vec3 resultingColor = imageLoad(inputSceneColor, targetPixel).rgb;

    pnanovdb_grid_handle_t grid = makeNanoGrid(0); 
    mat4 inverseModelMatrix = inverse(instanceModelMatrix[0]); 
    Ray worldRay = createRay(orgWorld, viewDirectionWorld.xyz); 
    Ray localRay = transformWorldRayToGridLocal(worldRay, inverseModelMatrix); 

    float t0 = 0;
    float t1 = 0;

    if (rayBoxIntersectWorld(grid, instanceModelMatrix[0], localRay, worldRay, t0, t1) && t0 < worldDepthDistance){
        resultingColor = vec3(1.0, 0.0, 0.0); 
    }

    imageStore(outputImage, targetPixel, vec4(resultingColor, 1.0));
}