#version 450

layout(local_size_x = 8, local_size_y = 8, local_size_z = 1) in;

struct Light_Type
{
    uint point;
    uint directional;
    uint spot;
};

struct Light
{
    vec4 position;
    vec4 direction;

    // properties
    vec4 ambient;
    vec4 diffuse;
    vec4 specular;
    // controls.x = inner cutoff angle
    // controls.y = outer cutoff angle
    vec4 controls;
    // settings.x = enabled
    // settings.y = type
    uvec4 settings;
};

layout(set = 0, binding = 0) uniform GlobalUniformBufferObject
{
    mat4 proj;
    mat4 view;
    mat4 inverseView;
} globalUbo;

layout(set = 0, binding = 1) uniform GlobalLightInfo{
    int numLights;
} lightInfo; 

layout(set = 0, binding = 2) readonly buffer GlobalLightBuffer{
    Light lights[];
 } lightList;

layout(set = 1, binding = 0) uniform additionalCameraInfo
{
    mat4 inverseProjMatrix;
    vec2 cameraDimensions;
    float aspectRatio;
    float farClipDist;
    float nearClipDist;
    float scale;
}
addCamInfo;
layout(std430, set = 1, binding = 1) buffer PNanoVDBBuffer{
    uint pnanovdb_buf_data[];
};

layout(set = 2, binding = 0, rgba8) uniform readonly image2D inputSceneColor;
layout(set = 2, binding = 1) uniform sampler2D inputSceneDepth;
layout(set = 2, binding = 2, rgba8) uniform writeonly image2D outputImage;

layout(set = 3, binding = 0) uniform InstanceModelMatrix
{
    mat4 instanceModelMatrix[1024];
};

layout(set = 3, binding = 1) uniform aabbInfo
{
    vec4 bounds[2];
}
aabb;

layout(set = 3, binding = 2) uniform FogControllerInfo
{
    float linearFog_nearDistance;
    float linearFog_farDistance;
    float expFog_density;
    float marchedFog_defaultDensity;
    float marchedFog_sigmaAbsorption;
    float marchedFog_sigmaScattering;
    float marchedFog_lightPropertyDirG;
    float marchedFog_stepSizeDist;
    float marchedFog_stepSizeDist_light;
    uint marchedFog_levelSet_maxNumSteps;
    uint gridType;
}
fogInfo;

#include "PNanoVDB.h"
#include "volume_helpers.comp"


vec4 getClipSpaceCoordsFromPixel(const ivec2 pixelCoords, const float ndz){
    // 1) Build NDC coordinates in [−1, +1]
    float ndcX = ((float(pixelCoords.x) + 0.5) / addCamInfo.cameraDimensions.x) * 2.0 - 1.0;
    float ndcY = ((float(pixelCoords.y) + 0.5) / addCamInfo.cameraDimensions.y) * 2.0 - 1.0;

    // Vulkan's Y axis is flipped compared to OpenGL
    ndcY = -ndcY; 

    // 2) Reconstruct clip-space with Z = −1 (the near plane), W = 1
    return vec4(ndcX, ndcY, ndz, 1.0);
}

vec4 getWorldPositionFromClip(const vec4 clipCoords){
    // 3) Go back to view-space:
    vec4 viewPositionWorld = addCamInfo.inverseProjMatrix * clipCoords;

    return viewPositionWorld / viewPositionWorld.w; 
}

vec4 getWorldViewDirection(const vec4 viewPositionWorld){
    return vec4(normalize((globalUbo.inverseView * vec4(viewPositionWorld.xyz, 0.0)).xyz), 0);
}

vec4 getWorldOrigin(){
    return vec4((globalUbo.inverseView * vec4(0.0, 0.0, 0.0, 1.0)).xyz, 1.0);
}

ivec2 getTargetPixelCoords()
{
    return ivec2((gl_LocalInvocationID.x) + ((gl_WorkGroupID.x) * 8),
                 (gl_LocalInvocationID.y) + ((gl_WorkGroupID.y) * 8));
}

float linearizeDepth(const float depth, const float camNearClipDist, const float camFarClipDist)
{
    /* convert depth value back to linear space -- based on proj matrix
    Source: http://www.songho.ca/opengl/gl_projectionmatrix.html
    Source2: https://learnopengl.com/Advanced-OpenGL/Depth-testing
    */
    return (camNearClipDist * camFarClipDist) / (camFarClipDist - depth * (camFarClipDist - camNearClipDist));
}

bool checkForThreadOutsideOfTarget()
{
    ivec2 imageSize = imageSize(inputSceneColor);
    uvec2 coords = gl_GlobalInvocationID.xy;
    if (coords.x > imageSize.x || coords.y > imageSize.y)
    {
        return false;
    }

    return true;
}

vec3 shadeSurface(const vec3 position, const vec3 normal){
    const vec3 volumeColor = vec3(1.0, 1.0, 1.0); 

    vec3 color = vec3(0.0, 0.0, 0.0);

    for (int i = 0; i < lightInfo.numLights; i++ ){
        const vec3 lightDir = normalize(lightList.lights[i].position.xyz - position);
        const float diffuse = max(dot(normal, lightDir), 0.0); 

        color += volumeColor * lightList.lights[i].diffuse.rgb * diffuse;
        color += (0.25 * lightList.lights[i].ambient.rgb); 
    }

    return color; 
}

vec3 estimateNormal(in pnanovdb_grid_handle_t grid, const vec3 position, const float voxSize, const float volumeUniformScale, const mat4 inverseModelMatrix){
    float eps = voxSize * 0.5 * volumeUniformScale; 

    return normalize(vec3(
        gridReadAt(grid, position + vec3(eps, 0, 0), inverseModelMatrix, volumeUniformScale) - gridReadAt(grid, position - vec3(eps, 0, 0), inverseModelMatrix, volumeUniformScale),
        gridReadAt(grid, position + vec3(0, eps, 0), inverseModelMatrix, volumeUniformScale) - gridReadAt(grid, position - vec3(0, eps, 0), inverseModelMatrix, volumeUniformScale),
        gridReadAt(grid, position + vec3(0, 0, eps), inverseModelMatrix, volumeUniformScale) - gridReadAt(grid, position - vec3(0, 0, eps), inverseModelMatrix, volumeUniformScale)
    ));
}

vec3 refineSurfacePosition(in pnanovdb_grid_handle_t grid, const Ray ray, vec3 position, float t, float threshold, const float voxSize, const float volumeUniformScale, const mat4 inverseModelMatrix){
    const float approachStepSize = 0.25 * voxSize; 

    for (int i = 0; i < 10; i++){
        float sdf = gridReadAt(grid, position.xyz, inverseModelMatrix,volumeUniformScale);

        if (abs(sdf) < threshold){
            break;
        }

        position -= (sdf * approachStepSize) * ray.direction.xyz; 
    }

    return position; 
}

//sphere ray marching application on level set nanoVDB volume
vec3 forwardMarchLevelSet(in pnanovdb_grid_handle_t grid, const vec3 viewDirection, 
                            const vec3 backgroundColor, const Ray worldRay, 
                            const mat4 inverseModelMatrix,
                            const float volumeUniformScale, 
                            const float t0, const float t1,  
                            const float cutOffDistance, const uint maxNumSteps)
{
    const float voxSize = float(pnanovdb_grid_get_voxel_size(nanoVDBBuffer, grid, 0));
    const float threshold = voxSize * 2.0;
    const float stepSizeMultiplier = 1.0; 

    vec3 resultingColor = backgroundColor;
    vec4 previousPosition; 
    float t = t0; 
    float previousSDF = 0; 

    for (uint i = 0; i < 1000; i++){
        vec4 position = worldRay.origin + ((t) * worldRay.direction); 

        float sdf = gridReadAt(grid, position.xyz, inverseModelMatrix, volumeUniformScale); 

        //check for if beyond range of bounding box
        if (t > t1 || t > cutOffDistance){
            break;
        }

        //check for change in sign of sdf function, stepped too far 
        if (previousSDF * sdf < 0 || abs(sdf) < threshold){
            vec3 refinedPosition = refineSurfacePosition(grid, worldRay, position.xyz, t, threshold, voxSize, volumeUniformScale, inverseModelMatrix);
            vec3 normal = estimateNormal(grid, refinedPosition, voxSize, volumeUniformScale, inverseModelMatrix); 
            resultingColor = shadeSurface(refinedPosition, normal); 
            break;
        }

        previousPosition = position;
        previousSDF = sdf;

        float stepSize = clamp(sdf, voxSize * 0.5, voxSize * 10.0); 
        t += stepSize;
    }

    return clamp(resultingColor, 0.0, 1.0); 
}

void main()
{
    if (!checkForThreadOutsideOfTarget())
        return;

    const ivec2 targetPixel = getTargetPixelCoords();
    float targetPixelInputDepth = texelFetch(inputSceneDepth, targetPixel, 0).r;

    const vec4 clipSpace = getClipSpaceCoordsFromPixel(targetPixel, targetPixelInputDepth); 
    const vec4 viewPositionWorld = getWorldPositionFromClip(clipSpace);
    const vec4 orgWorld = getWorldOrigin(); 
    const vec4 viewDirectionWorld = getWorldViewDirection(viewPositionWorld); 
    const float worldDepthDistance = length(viewPositionWorld.xyz - viewDirectionWorld.xyz); 

    const vec3 imgColor = vec3(imageLoad(inputSceneColor, targetPixel).rgb);
    vec3 resultingColor = imgColor;

    pnanovdb_grid_handle_t grid = makeNanoGrid(0);

    const mat4 inverseModelMatrix = inverse(instanceModelMatrix[0]); 
    Ray worldRay = createRay(orgWorld, viewDirectionWorld.xyz);  
    Ray gridLocalRay = transformWorldRayToGridLocal(worldRay, inverseModelMatrix); 

    float t0 = 0;
    float t1 = 0;

    const float scale = extractUniformVolumeScale(instanceModelMatrix[0]);
    if (rayBoxIntersect(grid, gridLocalRay, inverseModelMatrix, t0, t1) && t0 < worldDepthDistance){
        resultingColor = forwardMarchLevelSet(grid,
            viewDirectionWorld.xyz, 
            imgColor.xyz, worldRay, 
            inverseModelMatrix, 
            scale,
            t0, t1, worldDepthDistance, 
            fogInfo.marchedFog_levelSet_maxNumSteps);
    }

    imageStore(outputImage, targetPixel, vec4(resultingColor, 1.0));
}