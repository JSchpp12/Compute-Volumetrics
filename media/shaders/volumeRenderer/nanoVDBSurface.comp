#version 450

layout(local_size_x = 8, local_size_y = 8, local_size_z = 1) in;

struct Light_Type
{
    uint point;
    uint directional;
    uint spot;
};

struct Light
{
    vec4 position;
    vec4 direction;

    // properties
    vec4 ambient;
    vec4 diffuse;
    vec4 specular;
    // controls.x = inner cutoff angle
    // controls.y = outer cutoff angle
    vec4 controls;
    // settings.x = enabled
    // settings.y = type
    uvec4 settings;
};

layout(set = 0, binding = 0) uniform GlobalUniformBufferObject
{
    mat4 proj;
    mat4 view;
    mat4 inverseView;
} globalUbo;

layout(set = 0, binding = 1) uniform GlobalLightInfo{
    int numLights;
} lightInfo; 

layout(set = 0, binding = 2) readonly buffer GlobalLightBuffer{
    Light lights[];
 } lightList;

layout(set = 1, binding = 0) uniform additionalCameraInfo
{
    mat4 inverseProjMatrix;
    vec2 cameraDimensions;
    float aspectRatio;
    float farClipDist;
    float nearClipDist;
    float scale;
}
addCamInfo;
layout(std430, set = 1, binding = 1) buffer PNanoVDBBuffer{
    uint pnanovdb_buf_data[];
};

layout(set = 2, binding = 0, rgba8) uniform readonly image2D inputSceneColor;
layout(set = 2, binding = 1) uniform sampler2D inputSceneDepth;
layout(set = 2, binding = 2, rgba8) uniform writeonly image2D outputImage;

layout(set = 3, binding = 0) uniform InstanceModelMatrix
{
    mat4 modelMatrix[1024];
};

layout(set = 3, binding = 1) uniform aabbInfo
{
    vec4 bounds[2];
}
aabb;

layout(set = 3, binding = 2) uniform FogControllerInfo
{
    float linearFog_nearDistance;
    float linearFog_farDistance;
    float expFog_density;
    float marchedFog_defaultDensity;
    float marchedFog_sigmaAbsorption;
    float marchedFog_sigmaScattering;
    float marchedFog_lightPropertyDirG;
    float marchedFog_stepSizeDist;
    float marchedFog_stepSizeDist_light;
    uint marchedFog_levelSet_maxNumSteps;
    uint gridType;
}
fogInfo;

struct Ray
{
    vec4 origin;
    vec4 direction;
    vec4 invDirection;
    bool signed[3];
};

#include "PNanoVDB.h"
#include "volume_helpers.comp"

Ray createRay(const vec4 origin, const vec4 direction)
{
    vec3 invDir = vec3(1.0 / direction.x, 1.0 / direction.y, 1.0 / direction.z);

    return Ray(origin, direction, vec4(invDir, 0.0),
               bool[3](bool(invDir.x < 0), bool(invDir.y < 0), bool(invDir.z < 0)));
}

vec4 getClipSpaceCoordsFromPixel(const ivec2 pixelCoords, const float ndz){
    // 1) Build NDC coordinates in [−1, +1]
    float ndcX = ((float(pixelCoords.x) + 0.5) / addCamInfo.cameraDimensions.x) * 2.0 - 1.0;
    float ndcY = ((float(pixelCoords.y) + 0.5) / addCamInfo.cameraDimensions.y) * 2.0 - 1.0;

    // Vulkan's Y axis is flipped compared to OpenGL
    ndcY = -ndcY; 

    // 2) Reconstruct clip-space with Z = −1 (the near plane), W = 1
    return vec4(ndcX, ndcY, ndz, 1.0);
}

vec4 getWorldPositionFromClip(const vec4 clipCoords){
    // 3) Go back to view-space:
    vec4 viewPositionWorld = addCamInfo.inverseProjMatrix * clipCoords;

    return viewPositionWorld / viewPositionWorld.w; 
}

vec4 getWorldViewDirection(const vec4 viewPositionWorld){
    return vec4(normalize((globalUbo.inverseView * vec4(viewPositionWorld.xyz, 0.0)).xyz), 0);
}

vec4 getWorldOrigin(){
    return vec4((globalUbo.inverseView * vec4(0.0, 0.0, 0.0, 1.0)).xyz, 1.0);
}

ivec2 getTargetPixelCoords()
{
    return ivec2((gl_LocalInvocationID.x) + ((gl_WorkGroupID.x) * 8),
                 (gl_LocalInvocationID.y) + ((gl_WorkGroupID.y) * 8));
}

float linearizeDepth(const float depth, const float camNearClipDist, const float camFarClipDist)
{
    /* convert depth value back to linear space -- based on proj matrix
    Source: http://www.songho.ca/opengl/gl_projectionmatrix.html
    Source2: https://learnopengl.com/Advanced-OpenGL/Depth-testing
    */
    return (camNearClipDist * camFarClipDist) / (camFarClipDist - depth * (camFarClipDist - camNearClipDist));
}

bool checkForThreadOutsideOfTarget()
{
    ivec2 imageSize = imageSize(inputSceneColor);
    uvec2 coords = gl_GlobalInvocationID.xy;
    if (coords.x > imageSize.x || coords.y > imageSize.y)
    {
        return false;
    }

    return true;
}

bool rayBoxIntersect(in pnanovdb_grid_handle_t grid, in Ray ray, inout float t0, inout float t1)
{
    vec3 bounds[2];
    bounds[0] = vec3(
        float(pnanovdb_grid_get_world_bbox(nanoVDBBuffer, grid, 0)),
        float(pnanovdb_grid_get_world_bbox(nanoVDBBuffer, grid, 1)),
        float(pnanovdb_grid_get_world_bbox(nanoVDBBuffer, grid, 2))
    );
    bounds[1] = vec3(
        float(pnanovdb_grid_get_world_bbox(nanoVDBBuffer, grid, 3)),
        float(pnanovdb_grid_get_world_bbox(nanoVDBBuffer, grid, 4)), 
        float(pnanovdb_grid_get_world_bbox(nanoVDBBuffer, grid, 5))
    );

    float tmin = -(1.0 / 0.0);
    float tmax = (1.0 / 0.0);
    float txmin = 0, txmax = 0, tymin = 0, tymax = 0, tzmin = 0, tzmax = 0;

    txmin = (bounds[int(ray.signed[0])].x - ray.origin.x) * ray.invDirection.x;
    txmax = (bounds[int(!ray.signed[0])].x - ray.origin.x) * ray.invDirection.x;

    tmin = min(txmin, txmax);
    tmax = max(txmin, txmax);

    tymin = (bounds[int(ray.signed[1])].y - ray.origin.y) * ray.invDirection.y;
    tymax = (bounds[int(!ray.signed[1])].y - ray.origin.y) * ray.invDirection.y;

    tmin = max(tmin, min(tymin, tymax));
    tmax = min(tmax, max(tymin, tymax));

    tzmin = (bounds[int(ray.signed[2])].z - ray.origin.z) * ray.invDirection.z;
    tzmax = (bounds[int(!ray.signed[2])].z - ray.origin.z) * ray.invDirection.z;

    tmin = max(tmin, min(tzmin, tzmax));
    tmax = min(tmax, max(tzmin, tzmax));

    t0 = tmin;
    t1 = tmax;

    return tmax >= max(0.0, tmin);
}

vec3 shadeSurface(const vec3 position, const vec3 normal){
    const vec3 volumeColor = vec3(1.0, 1.0, 1.0); 

    vec3 color = vec3(0.0, 0.0, 0.0);

    for (int i = 0; i < lightInfo.numLights; i++ ){
        vec3 lightDir = normalize(lightList.lights[i].position.xyz - position);
        float diffuse = max(dot(-normal, lightDir), 0.0); 

        color += volumeColor * lightList.lights[i].diffuse.xyz * diffuse;
        color += (0.25 * lightList.lights[i].ambient.rgb); 
    }

    return color; 
}

vec3 estimateNormal(in pnanovdb_grid_handle_t grid, vec3 position, const float voxSize){
    float eps = voxSize * 0.5; 

    return normalize(vec3(
        gridReadAt(grid, position + vec3(eps, 0, 0)) - gridReadAt(grid, position - vec3(eps, 0, 0)),
        gridReadAt(grid, position + vec3(0, eps, 0)) - gridReadAt(grid, position - vec3(0, eps, 0)),
        gridReadAt(grid, position + vec3(0, 0, eps)) - gridReadAt(grid, position - vec3(0, 0, eps))
    ));
}

vec3 refineSurfacePosition(in pnanovdb_grid_handle_t grid, const Ray ray, vec3 position, float t, float threshold, const float voxSize){
    const float approachStepSize = 0.25 * voxSize; 

    for (int i = 0; i < 10; i++){
        float sdf = gridReadAt(grid, position);

        if (abs(sdf) < threshold){
            break;
        }

        position -= (sdf * approachStepSize) * ray.direction.xyz; 
    }

    return position; 
}


//sphere ray marching application on level set nanoVDB volume
vec3 forwardMarchLevelSet(in pnanovdb_grid_handle_t grid, const vec3 viewDirection, 
                            const vec3 backgroundColor, const Ray ray,
                            const float t0, const float t1,  
                            const float cutOffDistance, const uint maxNumSteps)
{
    const float voxSize = float(pnanovdb_grid_get_voxel_size(nanoVDBBuffer, grid, 0));
    const float threshold = voxSize * 2.0;
    const float stepSizeMultiplier = 1.0; 

    vec3 resultingColor = backgroundColor;
    vec3 previousPosition; 
    float t = t0; 
    float previousSDF = 0; 

    for (uint i = 0; i < 1000; i++){
        vec3 position = ray.origin.xyz + ((t) * ray.direction.xyz); 

        float sdf = gridReadAt(grid, position); 

        //check for if beyond range of bounding box
        if (t > t1){
            break;
        }

        //check for change in sign of sdf function, stepped too far 
        if (previousSDF * sdf < 0 || abs(sdf) < threshold){
            vec3 refinedPosition = refineSurfacePosition(grid, ray, position, t, threshold, voxSize);
            vec3 normal = estimateNormal(grid, refinedPosition, voxSize); 
            resultingColor = shadeSurface(refinedPosition, normal); 
            break;
        }

        previousPosition = position;
        previousSDF = sdf;

        float stepSize = clamp(sdf * stepSizeMultiplier, voxSize * 0.5, voxSize * 10.0);
        t += stepSize;
    }

    return clamp(resultingColor, 0.0, 1.0); 
}

void main()
{
    if (!checkForThreadOutsideOfTarget())
        return;

    const ivec2 targetPixel = getTargetPixelCoords();
    float targetPixelInputDepth = texelFetch(inputSceneDepth, targetPixel, 0).r;

    const vec4 clipSpace = getClipSpaceCoordsFromPixel(targetPixel, targetPixelInputDepth); 
    const vec4 viewPositionWorld = getWorldPositionFromClip(clipSpace);
    const vec4 orgWorld = getWorldOrigin(); 
    const vec4 viewDirectionWorld = getWorldViewDirection(viewPositionWorld); 
    const float worldDepthDistance = length(viewPositionWorld.xyz - viewDirectionWorld.xyz); 

    const vec3 imgColor = vec3(imageLoad(inputSceneColor, targetPixel).rgb);
    vec3 resultingColor = imgColor;

    pnanovdb_grid_handle_t grid = makeNanoGrid(0); 

    Ray camRay = createRay(orgWorld, viewDirectionWorld);

    float t0 = 0;
    float t1 = 0;

    if (rayBoxIntersect(grid, camRay, t0, t1) && t0 < worldDepthDistance){
        //need to get world distance from depth buffer value 
        //ray marching algorithm happens in world space...
        // const float worldCutoffPoint = camRay.origin + camRay.direction 
        
        resultingColor = forwardMarchLevelSet(grid,
            viewDirectionWorld.xyz, 
            imgColor, camRay, t0, t1, worldDepthDistance, 
            fogInfo.marchedFog_levelSet_maxNumSteps);
    }

    imageStore(outputImage, targetPixel, vec4(resultingColor, 1.0));
}