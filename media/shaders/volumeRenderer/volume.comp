#version 450

const float PI = 3.1415926535897932384626433832795;

layout(local_size_x = 8, local_size_y = 8, local_size_z = 1) in;

struct Light_Type
{
    uint point;
    uint directional;
    uint spot;
};

struct Light
{
    vec4 position;
    vec4 direction;

    // properties
    vec4 ambient;
    vec4 diffuse;
    vec4 specular;
    // controls.x = inner cutoff angle
    // controls.y = outer cutoff angle
    vec4 controls;
    // settings.x = enabled
    // settings.y = type
    uvec4 settings;
};

layout(set = 0, binding = 0) uniform GlobalUniformBufferObject
{
    mat4 proj;
    mat4 view;
    mat4 invView;
} globalUbo;

layout(set = 0, binding = 1) uniform GlobalLightInfo{
    int numLights;
} lightInfo; 

layout(set = 0, binding = 2) readonly buffer GlobalLightBuffer{
    Light lights[];
 } lightList;

layout(set = 1, binding = 0) uniform additionalCameraInfo
{
    mat4 invProj;
    vec2 cameraDimensions;
    float aspectRatio;
    float farClipDist;
    float nearClipDist;
    float scale;
}
addCamInfo;
layout(std430, set = 1, binding = 1) buffer PNanoVDBBuffer{
    uint pnanovdb_buf_data[];
};

layout(set = 2, binding = 0, rgba8) uniform readonly image2D inputSceneColor;
layout(set = 2, binding = 1) uniform sampler2D inputSceneDepth;
layout(set = 2, binding = 2, rgba8) uniform writeonly image2D outputImage;

layout(set = 3, binding = 0) uniform InstanceModelMatrix
{
    mat4 instanceModelMatrix[1024];
};

layout(set = 3, binding = 1) uniform aabbInfo
{
    vec4 bounds[2];
}
aabb;

layout(set = 3, binding = 2) uniform FogControllerInfo
{
    float linearFog_nearDistance;
    float linearFog_farDistance;
    float expFog_density;
    float marchedFog_defaultDensity;
    float marchedFog_sigmaAbsorption;
    float marchedFog_sigmaScattering;
    float marchedFog_lightPropertyDirG;
    float marchedFog_stepSizeDist;
    float marchedFog_stepSizeDist_light;
    uint marchedFog_levelSet_maxNumSteps;
    uint gridType;
}
fogInfo;

#include "PNanoVDB.h"
#include "volume_helpers.comp"

vec4 getClipSpaceCoordsFromPixel(const ivec2 pixelCoords, const uvec2 resolution, const float depth){
    vec2 uv = (vec2(pixelCoords) + 0.5) / vec2(resolution);
    uv = uv * 2.0 - 1.0; 
    float clipZ = depth * 2.0 - 1.0; 
 
    return vec4(uv.x, uv.y, clipZ, 1.0);  
}

void getSceneViewInfoForPix(in const ivec2 pixelCoords, in const uvec2 resolution, in float depth, out vec3 orgWorld, out vec3 viewDirWorld) {
    vec4 clipPos = getClipSpaceCoordsFromPixel(pixelCoords, resolution, depth);

    vec4 viewPos = addCamInfo.invProj * clipPos;
    viewPos /= viewPos.w;

    vec3 cameraPosWorld = (globalUbo.invView * vec4(0.0, 0.0, 0.0, 1.0)).xyz;

    // Compute ray direction
    vec3 rayDirView = normalize(viewPos.xyz);
    vec3 rayDirWorld = normalize((globalUbo.invView * vec4(rayDirView, 0.0)).xyz); // transform to world space
    
    orgWorld = cameraPosWorld;
    viewDirWorld = rayDirWorld;
}

ivec2 getTargetPixelCoords()
{
    return ivec2((gl_LocalInvocationID.x) + ((gl_WorkGroupID.x) * 8),
                 (gl_LocalInvocationID.y) + ((gl_WorkGroupID.y) * 8));
}

float linearizeDepth(const float depth, const float camNearClipDist, const float camFarClipDist)
{
    /* convert depth value back to linear space -- based on proj matrix
    Source: http://www.songho.ca/opengl/gl_projectionmatrix.html
    Source2: https://learnopengl.com/Advanced-OpenGL/Depth-testing
    */
    return (camNearClipDist * camFarClipDist) / (camFarClipDist - depth * (camFarClipDist - camNearClipDist));
}

bool checkForThreadOutsideOfTarget()
{
    ivec2 imageSize = imageSize(inputSceneColor);
    uvec2 coords = gl_GlobalInvocationID.xy;
    if (coords.x > imageSize.x || coords.y > imageSize.y)
    {
        return false;
    }

    return true;
}

float applyHenyeyGreensteinPhase(const vec3 viewDirection, const vec3 lightDirection, const float gValue){
    const float cosTheta = clamp(dot(viewDirection, lightDirection), -1.0, 1.0); 
    const float denom = pow(1 + gValue * gValue - 2 * gValue * cosTheta, 1.5);
    return float(1) / (4 *PI) * (1 - gValue * gValue) / denom; 
}

float rand(vec2 co){
    return fract(sin(dot(co, vec2(12.9898, 78.233))) * 43758.5453);
}

vec3 forwardMarch(in pnanovdb_grid_handle_t grid, const vec3 backgroundColor, const Ray ray, const float t0, const float t1,
                  const mat4 inverseModelMatrix, const float volumeUniformScale, float sigmaAbsorption, const float sigmaScattering, const float lightPropertyDir_g,
                  float mainStepSize, const float lightStepSize, const float cutOffDistance)
{ 
    sigmaAbsorption = 0.1; 
    mainStepSize = 0.2; 

    // const float endDist = min(t1, cutOffDistance); 
    const int fittedNumSteps = max(1, int(ceil(t1 / mainStepSize)));
    const float middleStepSizeDist = mainStepSize / 2.0; 

	float transparency = 1.0;
    vec3 resultingRadiance = vec3(0.0); 
    for (int i = 0; i < fittedNumSteps; i++){
        // setting to middle
        const float t = t0 + mainStepSize * (i + middleStepSizeDist);
		const vec3 worldPos = ray.origin.xyz + t * ray.direction.xyz; 
        float sampleTransparency = exp(-mainStepSize * sigmaAbsorption); 
        transparency *= sampleTransparency; 

		for (int j = 0; j < lightInfo.numLights; j++){
            const vec3 lightPos = lightList.lights[j].position.xyz;

            //might need to check if light is within volume later

            const Ray rayToLight = createRay(worldPos, normalize(lightPos - worldPos));
            const Ray rayToLightLocal = transformWorldRayToGridLocal(rayToLight, inverseModelMatrix); 

            float lt0 = 0;
            float lt1 = 0;  
            float tau = 0.0; 
            if (rayBoxIntersect(grid, rayToLight, lt0, lt1)){ 
                //check if light is within the bounds of the volume and clamp to that distance rather than going all the way through
                float lightAttenuation = exp(-lt1 * sigmaAbsorption);

                resultingRadiance += transparency * lightList.lights[j].ambient.rgb * lightAttenuation * mainStepSize; 
            }
		}
    }

    return backgroundColor * transparency + resultingRadiance; 
}

void main()
{
    uvec2 gid = gl_GlobalInvocationID.xy;
    uvec2 size = uvec2(addCamInfo.cameraDimensions.xy);
    if (any(greaterThanEqual(gid, size))) return;

    ivec2 targetPixel = getTargetPixelCoords(); 
    pnanovdb_grid_handle_t grid = makeNanoGrid(0);
    const float volumeUniformScale = extractUniformVolumeScale(instanceModelMatrix[0]);
    
    float targetPixelInputDepth = texelFetch(inputSceneDepth, targetPixel, 0).r;
    const float linearDepth = linearizeDepth(targetPixelInputDepth, addCamInfo.nearClipDist, addCamInfo.farClipDist); 
    vec3 resultingColor = imageLoad(inputSceneColor, targetPixel).rgb;

    vec3 viewDirScene = vec3(0.0); 
    vec3 orgScene = vec3(0.0);
    getSceneViewInfoForPix(targetPixel, uvec2(addCamInfo.cameraDimensions.x, addCamInfo.cameraDimensions.y), targetPixelInputDepth, orgScene, viewDirScene); 

    const mat4 inverseModelMatrix = inverse(instanceModelMatrix[0]); 
    Ray worldRay = createRay(orgScene.xyz, viewDirScene.xyz);  
    Ray localRay = transformWorldRayToGridLocal(worldRay, inverseModelMatrix); 

    float t0 = 0;
    float t1 = 0;

    if (rayBoxIntersect(grid, localRay, t0, t1) && t0 < linearDepth){
        resultingColor = forwardMarch(grid,
            resultingColor, 
            localRay, 
            t0, 
            t1, 
            inverseModelMatrix, 
            volumeUniformScale,
            fogInfo.marchedFog_sigmaAbsorption,
            fogInfo.marchedFog_sigmaScattering,
            fogInfo.marchedFog_lightPropertyDirG, 
            fogInfo.marchedFog_stepSizeDist,
            fogInfo.marchedFog_stepSizeDist_light,
            linearDepth
        );
    }

    imageStore(outputImage, targetPixel, vec4(resultingColor, 1.0));
}