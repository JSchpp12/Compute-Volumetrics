#version 450

const float PI = 3.1415926535897932384626433832795;

layout(local_size_x = 8, local_size_y = 8, local_size_z = 1) in;

struct Light_Type
{
    uint point;
    uint directional;
    uint spot;
};

struct Light
{
    vec4 position;
    vec4 direction;

    // properties
    vec4 ambient;
    vec4 diffuse;
    vec4 specular;
    // controls.x = inner cutoff angle
    // controls.y = outer cutoff angle
    vec4 controls;
    // settings.x = enabled
    // settings.y = type
    uvec4 settings;
};

layout(set = 0, binding = 0) uniform GlobalUniformBufferObject
{
    mat4 proj;
    mat4 view;
    mat4 inverseView;
} globalUbo;

layout(set = 0, binding = 1) uniform GlobalLightInfo{
    int numLights;
} lightInfo; 

layout(set = 0, binding = 2) readonly buffer GlobalLightBuffer{
    Light lights[];
 } lightList;

layout(set = 1, binding = 0) uniform additionalCameraInfo
{
    mat4 inverseProjMatrix;
    vec2 cameraDimensions;
    float aspectRatio;
    float farClipDist;
    float nearClipDist;
    float scale;
}
addCamInfo;
layout(std430, set = 1, binding = 1) buffer PNanoVDBBuffer{
    uint pnanovdb_buf_data[];
};

layout(set = 2, binding = 0, rgba8) uniform readonly image2D inputSceneColor;
layout(set = 2, binding = 1) uniform sampler2D inputSceneDepth;
layout(set = 2, binding = 2, rgba8) uniform writeonly image2D outputImage;

layout(set = 3, binding = 0) uniform InstanceModelMatrix
{
    mat4 instanceModelMatrix[1024];
};

layout(set = 3, binding = 1) uniform aabbInfo
{
    vec4 bounds[2];
}
aabb;

layout(set = 3, binding = 2) uniform FogControllerInfo
{
    float linearFog_nearDistance;
    float linearFog_farDistance;
    float expFog_density;
    float marchedFog_defaultDensity;
    float marchedFog_sigmaAbsorption;
    float marchedFog_sigmaScattering;
    float marchedFog_lightPropertyDirG;
    float marchedFog_stepSizeDist;
    float marchedFog_stepSizeDist_light;
    uint marchedFog_levelSet_maxNumSteps;
    uint gridType;
}
fogInfo;

#include "PNanoVDB.h"
#include "volume_helpers.comp"

vec4 getClipSpaceCoordsFromPixel(const ivec2 pixelCoords, const float ndz){
    // 1) Build NDC coordinates in [−1, +1]
    float ndcX = ((float(pixelCoords.x) + 0.5) / addCamInfo.cameraDimensions.x) * 2.0 - 1.0;
    float ndcY = ((float(pixelCoords.y) + 0.5) / addCamInfo.cameraDimensions.y) * 2.0 - 1.0;

    // Vulkan's Y axis is flipped compared to OpenGL
    ndcY = -ndcY; 

    // 2) Reconstruct clip-space with Z = −1 (the near plane), W = 1
    return vec4(ndcX, ndcY, ndz, 1.0);
}

vec4 getWorldPositionFromClip(const vec4 clipCoords){
    // 3) Go back to view-space:
    vec4 viewPositionWorld = addCamInfo.inverseProjMatrix * clipCoords;

    return viewPositionWorld / viewPositionWorld.w; 
}

vec4 getWorldViewDirection(const vec4 viewPositionWorld){
    return vec4(normalize((globalUbo.inverseView * vec4(viewPositionWorld.xyz, 0.0)).xyz), 0);
}

vec4 getWorldOrigin(){
    return vec4((globalUbo.inverseView * addCamInfo.inverseProjMatrix * vec4(0.0, 0.0, 0.0, 1.0)).xyz, 1.0);
}

ivec2 getTargetPixelCoords()
{
    return ivec2((gl_LocalInvocationID.x) + ((gl_WorkGroupID.x) * 8),
                 (gl_LocalInvocationID.y) + ((gl_WorkGroupID.y) * 8));
}

float linearizeDepth(const float depth, const float camNearClipDist, const float camFarClipDist)
{
    /* convert depth value back to linear space -- based on proj matrix
    Source: http://www.songho.ca/opengl/gl_projectionmatrix.html
    Source2: https://learnopengl.com/Advanced-OpenGL/Depth-testing
    */
    return (camNearClipDist * camFarClipDist) / (camFarClipDist - depth * (camFarClipDist - camNearClipDist));
}

bool checkForThreadOutsideOfTarget()
{
    ivec2 imageSize = imageSize(inputSceneColor);
    uvec2 coords = gl_GlobalInvocationID.xy;
    if (coords.x > imageSize.x || coords.y > imageSize.y)
    {
        return false;
    }

    return true;
}

float applyHenyeyGreensteinPhase(const vec3 viewDirection, const vec3 lightDirection, const float gValue){
    const float cosTheta = clamp(dot(viewDirection, lightDirection), -1.0, 1.0); 
    const float denom = pow(1 + gValue * gValue - 2 * gValue * cosTheta, 1.5);
    return float(1) / (4 *PI) * (1 - gValue * gValue) / denom; 
}

float rand(vec2 co){
    return fract(sin(dot(co, vec2(12.9898, 78.233))) * 43758.5453);
}

vec3 forwardMarch(in pnanovdb_grid_handle_t grid, const vec3 viewPositionWorld, const vec3 backgroundColor, const Ray ray, const float t0, const float t1,
                  const mat4 inverseModelMatrix, const float volumeUniformScale, float sigmaAbsorption, const float sigmaScattering, const float lightPropertyDir_g,
                  float mainStepSize, const float lightStepSize, const float cutOffDistance)
{ 
    sigmaAbsorption = 0.1; 
    mainStepSize = 0.2; 

    // const float endDist = min(t1, cutOffDistance); 
    const int fittedNumSteps = max(1, int(ceil(t1 / mainStepSize)));
    const float middleStepSizeDist = mainStepSize / 2.0; 

	float transparency = 1.0;
    vec3 resultingRadiance = vec3(0.0); 
    for (int i = 0; i < fittedNumSteps; i++){
        // setting to middle
        const float t = t0 + mainStepSize * (i + middleStepSizeDist);
		const vec3 worldPos = ray.origin.xyz + t * ray.direction.xyz; 
        float sampleTransparency = exp(-mainStepSize * sigmaAbsorption); 
        transparency *= sampleTransparency; 

		for (int j = 0; j < lightInfo.numLights; j++){
            const vec3 lightPos = lightList.lights[j].position.xyz;

            //might need to check if light is within volume later

            const Ray rayToLight = createRay(worldPos, normalize(lightPos - worldPos));
            const Ray rayToLightLocal = transformWorldRayToGridLocal(rayToLight, inverseModelMatrix); 

            float lt0 = 0;
            float lt1 = 0;  
            float tau = 0.0; 
            if (rayBoxIntersectWorld(grid, instanceModelMatrix[0], rayToLightLocal, rayToLight, lt0, lt1)){ 
                //check if light is within the bounds of the volume and clamp to that distance rather than going all the way through
                float lightAttenuation = exp(-lt1 * sigmaAbsorption);

                resultingRadiance += transparency * lightList.lights[j].ambient.rgb * lightAttenuation * mainStepSize; 
            }
		}
    }

    return backgroundColor * transparency + resultingRadiance; 
}

void main()
{
    if (!checkForThreadOutsideOfTarget())
        return;

    const ivec2 targetPixel = getTargetPixelCoords();
    float targetPixelInputDepth = texelFetch(inputSceneDepth, targetPixel, 0).r;

    const vec4 clipSpace = getClipSpaceCoordsFromPixel(targetPixel, targetPixelInputDepth); 
    const vec4 viewPositionWorld = getWorldPositionFromClip(clipSpace);
    const vec4 orgWorld = getWorldOrigin(); 
    const vec4 viewDirectionWorld = getWorldViewDirection(viewPositionWorld); 
    const float worldDepthDistance = length(viewPositionWorld.xyz - orgWorld.xyz); 

    vec3 resultingColor = imageLoad(inputSceneColor, targetPixel).rgb;

    pnanovdb_grid_handle_t grid = makeNanoGrid(0);

    const mat4 inverseModelMatrix = inverse(instanceModelMatrix[0]); 
    const Ray worldRay = createRay(orgWorld.xyz, viewDirectionWorld.xyz);  
    const Ray localRay = transformWorldRayToGridLocal(worldRay, inverseModelMatrix); 
    const float volumeUniformScale = extractUniformVolumeScale(instanceModelMatrix[0]); 

    float t0World = 0;
    float t1World = 0;

    if (rayBoxIntersectWorld(grid, inverseModelMatrix, localRay, worldRay, t0World, t1World) && t0World < worldDepthDistance){
        
        resultingColor = forwardMarch(grid,
            viewPositionWorld.xyz, 
            resultingColor, worldRay, 
            t0World, t1World, inverseModelMatrix, volumeUniformScale,
                                     fogInfo.marchedFog_sigmaAbsorption, fogInfo.marchedFog_sigmaScattering,
                                     fogInfo.marchedFog_lightPropertyDirG, fogInfo.marchedFog_stepSizeDist,
                                     fogInfo.marchedFog_stepSizeDist_light, 
                                     worldDepthDistance);
    }

    imageStore(outputImage, targetPixel, vec4(resultingColor, 1.0));
}